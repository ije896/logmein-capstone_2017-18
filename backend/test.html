<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<HTML>
<HEAD> <TITLE>curl - Tutorial</TITLE>
<meta content="text/html; charset=UTF-8" http-equiv="Content-Type">
<link rel="stylesheet" type="text/css" href="https://curl.haxx.se/curl.css">
<link rel="shortcut icon" href="https://curl.haxx.se/favicon.ico">
<link rel="icon" href="https://curl.haxx.se/logo/curl-symbol.svg" type="image/svg+xml">
</HEAD>
<body bgcolor="#ffffff" text="#000000">
<div class="main">
<div class="menu">
<a href="/docs/" class="menuitem" title="Documentation main page">Docs Overview</a>
<a href="/docs/comparison-table.html" class="menuitem" title="Compare curl to other tools">Comparison Table</a>
<a href="/docs/manpage.html" class="menuitem" title="Command line option reference">curl man page</a>
<a href="/docs/faq.html" class="menuitem" title="Frequently Asked Questions">FAQ</a>
<a href="/docs/httpscripting.html" class="itemselect">HTTP Scripting</a>
<a href="/docs/mk-ca-bundle.html" class="menuitem" title="Generate your own CA bundle">mk-ca-bundle</a>
<a href="/docs/manual.html" class="menuitem" title="A curl tutorial">Tutorial</a>
</div>
<div class="contents">
<div class="where"><a href="https://curl.haxx.se/">curl</a> / <a href="/docs/">Docs</a> / <a href="/docs/tooldocs.html">Tool Documentation</a> / <b>HTTP Scripting</b></div>
<h1> Using curl to automate HTTP jobs </h1>
<div class="relatedbox">
<b>Related:</b>
<br><a href="manpage.html">curl man page</a>
<br><a href="manual.html">Manual</a>
<br><a href="faq.html">FAQ</a>
</div>
<h2>HTTP Scripting</h2>
<p>
<a href="#Background">1.1</a> Background<br>
<a href="#The_HTTP_Protocol">1.2</a> The HTTP Protocol<br>
<a href="#See_the_Protocol">1.3</a> See the Protocol<br>
<a href="#See_the_Timing">1.4</a> See the Timing<br>
<a href="#See_the_Response">1.5</a> See the Response<br>
<h2>URL</h2>
<p>
<a href="#Spec">2.1</a> Spec<br>
<a href="#Host">2.2</a> Host<br>
<a href="#Port_number">2.3</a> Port number<br>
<a href="#User_name_and_password">2.4</a> User name and password<br>
<a href="#Path_part">2.5</a> Path part<br>
<h2>Fetch a page</h2>
<p>
<a href="#GET">3.1</a> GET<br>
<a href="#HEAD">3.2</a> HEAD<br>
<a href="#Multiple_URLs_in_a_single_comman">3.3</a> Multiple URLs in a single command line<br>
<a href="#Multiple_HTTP_methods_in_a_singl">3.4</a> Multiple HTTP methods in a single command line<br>
<h2>HTML forms</h2>
<p>
<a href="#Forms_explained">4.1</a> Forms explained<br>
<a href="#GET">4.2</a> GET<br>
<a href="#POST">4.3</a> POST<br>
<a href="#File_Upload_POST">4.4</a> File Upload POST<br>
<a href="#Hidden_Fields">4.5</a> Hidden Fields<br>
<a href="#Figure_Out_What_A_POST_Looks_Lik">4.6</a> Figure Out What A POST Looks Like<br>
<h2>HTTP upload</h2>
<p>
<a href="#PUT">5.1</a> PUT<br>
<h2>HTTP Authentication</h2>
<p>
<a href="#Basic_Authentication">6.1</a> Basic Authentication<br>
<a href="#Other_Authentication">6.2</a> Other Authentication<br>
<a href="#Proxy_Authentication">6.3</a> Proxy Authentication<br>
<a href="#Hiding_credentials">6.4</a> Hiding credentials<br>
<h2>More HTTP Headers</h2>
<p>
<a href="#Referer">7.1</a> Referer<br>
<a href="#User_Agent">7.2</a> User Agent<br>
<h2>Redirects</h2>
<p>
<a href="#Location_header">8.1</a> Location header<br>
<a href="#Other_redirects">8.2</a> Other redirects<br>
<h2>Cookies</h2>
<p>
<a href="#Cookie_Basics">9.1</a> Cookie Basics<br>
<a href="#Cookie_options">9.2</a> Cookie options<br>
<h2>HTTPS</h2>
<p>
<a href="#HTTPS_is_HTTP_secure">10.1</a> HTTPS is HTTP secure<br>
<a href="#Certificates">10.2</a> Certificates<br>
<h2>Custom Request Elements</h2>
<p>
<a href="#Modify_method_and_headers">11.1</a> Modify method and headers<br>
<a href="#More_on_changed_methods">11.2</a> More on changed methods<br>
<h2>Web Login</h2>
<p>
<a href="#Some_login_tricks">12.1</a> Some login tricks<br>
<h2>Debug</h2>
<p>
<a href="#Some_debug_tricks">13.1</a> Some debug tricks<br>
<h2>References</h2>
<p>
<a href="#Standards">14.1</a> Standards<br>
<a href="#Sites">14.2</a> Sites<br>
<hr>
 <h2>1. HTTP Scripting</h2><a name="Background"></a><h3>1.1 Background</h3>
<p> This document assumes that you're familiar with HTML and general networking.
<p> The increasing amount of applications moving to the web has made "HTTP
  Scripting" more frequently requested and wanted. To be able to automatically
   extract information from the web, to fake users, to post or upload data to
   web servers are all important tasks today.
 <p> Curl is a command line tool for doing all sorts of URL manipulations and
  transfers, but this particular document will focus on how to use it when
   doing HTTP requests for fun and profit. I'll assume that you know how to
   invoke 'curl --help' or 'curl --manual' to get basic information about it.
 <p> Curl is not written to do everything for you. It makes the requests, it gets
  the data, it sends data and it retrieves the information. You probably need
   to glue everything together using some kind of script language or repeated
   manual invokes.
 <a name="The_HTTP_Protocol"></a><h3>1.2 The HTTP Protocol</h3>
<p> HTTP is the protocol used to fetch data from web servers. It is a very simple
  protocol that is built upon TCP/IP. The protocol also allows information to
   get sent to the server from the client using a few different methods, as will
   be shown here.
 <p> HTTP is plain ASCII text lines being sent by the client to a server to
  request a particular action, and then the server replies a few text lines
   before the actual requested content is sent to the client.
 <p> The client, curl, sends a HTTP request. The request contains a method (like
  GET, POST, HEAD etc), a number of request headers and sometimes a request
   body. The HTTP server responds with a status line (indicating if things went
   well), response headers and most often also a response body. The "body" part
   is the plain data you requested, like the actual HTML or the image etc.
 <a name="See_the_Protocol"></a><h3>1.3 See the Protocol</h3>
<p>  Using curl's option --verbose (-v as a short option) will display what kind
   of commands curl sends to the server, as well as a few other informational
    texts.
 <p>  --verbose is the single most useful option when it comes to debug or even
   understand the curl&lt;-&gt;server interaction.
 <p>  Sometimes even --verbose is not enough. Then --trace and --trace-ascii offer
   even more details as they show EVERYTHING curl sends and receives. Use it
    like this:
 <pre>
 curl --trace-ascii debugdump.txt <a href="http://www.example.com/">http://www.example.com/</a>
</pre>
<a name="See_the_Timing"></a><h3>1.4 See the Timing</h3>
<p>  Many times you may wonder what exactly is taking all the time, or you just
   want to know the amount of milliseconds between two points in a
    transfer. For those, and other similar situations, the --trace-time option
    is what you need. It'll prepend the time to each trace output line:
 <pre>
 curl --trace-ascii d.txt --trace-time <a href="http://example.com/">http://example.com/</a>
</pre>
<a name="See_the_Response"></a><h3>1.5 See the Response</h3>
<p>  By default curl sends the response to stdout. You need to redirect it
   somewhere to avoid that, most often that is done with -o or -O.
 <h2>2. URL</h2><a name="Spec"></a><h3>2.1 Spec</h3>
<p> The Uniform Resource Locator format is how you specify the address of a
  particular resource on the Internet. You know these, you've seen URLs like
   <a href="https://curl.haxx.se">https://curl.haxx.se</a> or <a href="https://yourbank.com">https://yourbank.com</a> a million times. RFC 3986 is the
   canonical spec. And yeah, the formal name is not URL, it is URI.
 <a name="Host"></a><h3>2.2 Host</h3>
<p> The host name is usually resolved using DNS or your /etc/hosts file to an IP
  address and that's what curl will communicate with. Alternatively you specify
   the IP address directly in the URL instead of a name.
 <p> For development and other trying out situations, you can point to a different
  IP address for a host name than what would otherwise be used, by using curl's
   --resolve option:
 <pre>
 curl --resolve www.example.org:80:127.0.0.1 <a href="http://www.example.org/">http://www.example.org/</a>
</pre>
<a name="Port_number"></a><h3>2.3 Port number</h3>
<p> Each protocol curl supports operates on a default port number, be it over TCP
  or in some cases UDP. Normally you don't have to take that into
   consideration, but at times you run test servers on other ports or
   similar. Then you can specify the port number in the URL with a colon and a
   number immediately following the host name. Like when doing HTTP to port
   1234:
 <pre>
 curl <a href="http://www.example.org:1234/">http://www.example.org:1234/</a>
</pre>
<p> The port number you specify in the URL is the number that the server uses to
  offer its services. Sometimes you may use a local proxy, and then you may
   need to specify that proxy's port number separately for what curl needs to
   connect to locally. Like when using a HTTP proxy on port 4321:
 <pre>
 curl --proxy <a href="http://proxy.example.org:4321">http://proxy.example.org:4321</a> <a href="http://remote.example.org/">http://remote.example.org/</a>
</pre>
<a name="User_name_and_password"></a><h3>2.4 User name and password</h3>
<p> Some services are setup to require HTTP authentication and then you need to
  provide name and password which is then transferred to the remote site in
   various ways depending on the exact authentication protocol used.
 <p> You can opt to either insert the user and password in the URL or you can
  provide them separately:
 <pre>
 curl <a href="http://user:password">http://user:password</a>@example.org/
</pre>
<p> or
<pre>
 curl -u user:password <a href="http://example.org/">http://example.org/</a>
</pre>
<p> You need to pay attention that this kind of HTTP authentication is not what
  is usually done and requested by user-oriented web sites these days. They
   tend to use forms and cookies instead.
 <a name="Path_part"></a><h3>2.5 Path part</h3>
<p> The path part is just sent off to the server to request that it sends back
  the associated response. The path is what is to the right side of the slash
   that follows the host name and possibly port number.
 <h2>3. Fetch a page</h2><a name="GET"></a><h3>3.1 GET</h3>
<p> The simplest and most common request/operation made using HTTP is to GET a
  URL. The URL could itself refer to a web page, an image or a file. The client
   issues a GET request to the server and receives the document it asked for.
   If you issue the command line
 <pre>
 curl <a href="https://curl.haxx.se">https://curl.haxx.se</a>
</pre>
<p> you get a web page returned in your terminal window. The entire HTML document
  that that URL holds.
 <p> All HTTP replies contain a set of response headers that are normally hidden,
  use curl's --include (-i) option to display them as well as the rest of the
   document.
 <a name="HEAD"></a><h3>3.2 HEAD</h3>
<p> You can ask the remote server for ONLY the headers by using the --head (-I)
  option which will make curl issue a HEAD request. In some special cases
   servers deny the HEAD method while others still work, which is a particular
   kind of annoyance.
 <p> The HEAD method is defined and made so that the server returns the headers
  exactly the way it would do for a GET, but without a body. It means that you
   may see a Content-Length: in the response headers, but there must not be an
   actual body in the HEAD response.
 <a name="Multiple_URLs_in_a_single_comman"></a><h3>3.3 Multiple URLs in a single command line</h3>
<p> A single curl command line may involve one or many URLs. The most common case
  is probably to just use one, but you can specify any amount of URLs. Yes
   any. No limits. You'll then get requests repeated over and over for all the
   given URLs.
 <p> Example, send two GETs:
<p>    curl <a href="http://url1.example.com">http://url1.example.com</a> <a href="http://url2.example.com">http://url2.example.com</a>
<p> If you use --data to POST to the URL, using multiple URLs means that you send
  that same POST to all the given URLs.
 <p> Example, send two POSTs:
<p>    curl --data name=curl <a href="http://url1.example.com">http://url1.example.com</a> <a href="http://url2.example.com">http://url2.example.com</a>
<a name="Multiple_HTTP_methods_in_a_singl"></a><h3>3.4 Multiple HTTP methods in a single command line</h3>
<p> Sometimes you need to operate on several URLs in a single command line and do
  different HTTP methods on each. For this, you'll enjoy the --next option. It
   is basically a separator that separates a bunch of options from the next. All
   the URLs before --next will get the same method and will get all the POST
   data merged into one.
 <p> When curl reaches the --next on the command line, it'll sort of reset the
  method and the POST data and allow a new set.
 <p> Perhaps this is best shown with a few examples. To send first a HEAD and then
  a GET:
 <p>   curl -I <a href="http://example.com">http://example.com</a> --next <a href="http://example.com">http://example.com</a>
<p> To first send a POST and then a GET:
<p>   curl -d score=10 <a href="http://example.com/post.cgi">http://example.com/post.cgi</a> --next <a href="http://example.com/results.html">http://example.com/results.html</a>
<h2>4. HTML forms</h2><a name="Forms_explained"></a><h3>4.1 Forms explained</h3>
<p> Forms are the general way a web site can present a HTML page with fields for
  the user to enter data in, and then press some kind of 'OK' or 'Submit'
   button to get that data sent to the server. The server then typically uses
   the posted data to decide how to act. Like using the entered words to search
   in a database, or to add the info in a bug tracking system, display the entered
   address on a map or using the info as a login-prompt verifying that the user
   is allowed to see what it is about to see.
 <p> Of course there has to be some kind of program on the server end to receive
  the data you send. You cannot just invent something out of the air.
 <a name="GET"></a><h3>4.2 GET</h3>
<p>  A GET-form uses the method GET, as specified in HTML like:
<pre>
 &lt;form method="GET" action="junk.cgi"&gt;
 &lt;input type=text name="birthyear"&gt;
 &lt;input type=submit name=press value="OK"&gt;
 &lt;/form&gt;
</pre>
<p>  In your favorite browser, this form will appear with a text box to fill in
   and a press-button labeled "OK". If you fill in '1905' and press the OK
    button, your browser will then create a new URL to get for you. The URL will
    get "junk.cgi?birthyear=1905&amp;press=OK" appended to the path part of the
    previous URL.
 <p>  If the original form was seen on the page "www.hotmail.com/when/birth.html",
   the second page you'll get will become
    "www.hotmail.com/when/junk.cgi?birthyear=1905&amp;press=OK".
 <p>  Most search engines work this way.
<p>  To make curl do the GET form post for you, just enter the expected created
   URL:
 <pre>
 curl "<a href="http://www.hotmail.com/when/junk.cgi?birthyear=1905&amp;press">http://www.hotmail.com/when/junk.cgi?birthyear=1905&amp;press</a>=OK"
</pre>
<a name="POST"></a><h3>4.3 POST</h3>
<p>  The GET method makes all input field names get displayed in the URL field of
   your browser. That's generally a good thing when you want to be able to
    bookmark that page with your given data, but it is an obvious disadvantage
    if you entered secret information in one of the fields or if there are a
    large amount of fields creating a very long and unreadable URL.
 <p>  The HTTP protocol then offers the POST method. This way the client sends the
   data separated from the URL and thus you won't see any of it in the URL
    address field.
 <p>  The form would look very similar to the previous one:
<pre>
 &lt;form method="POST" action="junk.cgi"&gt;
 &lt;input type=text name="birthyear"&gt;
 &lt;input type=submit name=press value=" OK "&gt;
 &lt;/form&gt;
</pre>
<p>  And to use curl to post this form with the same data filled in as before, we
   could do it like:
 <pre>
 curl --data "birthyear=1905&amp;press=%20OK%20"  <a href="http://www.example.com/when.cgi">http://www.example.com/when.cgi</a>
</pre>
<p>  This kind of POST will use the Content-Type
   application/x-www-form-urlencoded and is the most widely used POST kind.
 <p>  The data you send to the server MUST already be properly encoded, curl will
   not do that for you. For example, if you want the data to contain a space,
    you need to replace that space with %20 etc. Failing to comply with this
    will most likely cause your data to be received wrongly and messed up.
 <p>  Recent curl versions can in fact url-encode POST data for you, like this:
<pre>
 curl --data-urlencode "name=I am Daniel" <a href="http://www.example.com">http://www.example.com</a>
</pre>
<p>  If you repeat --data several times on the command line, curl will
   concatenate all the given data pieces - and put a '&amp;' symbol between each
    data segment.
 <a name="File_Upload_POST"></a><h3>4.4 File Upload POST</h3>
<p>  Back in late 1995 they defined an additional way to post data over HTTP. It
   is documented in the RFC 1867, why this method sometimes is referred to as
    RFC1867-posting.
 <p>  This method is mainly designed to better support file uploads. A form that
   allows a user to upload a file could be written like this in HTML:
 <p>    &lt;form method="POST" enctype='multipart/form-data' action="upload.cgi"&gt;
<pre>
 &lt;input type=file name=upload&gt;
 &lt;input type=submit name=press value="OK"&gt;
</pre>
     &lt;/form&gt;
 <p>  This clearly shows that the Content-Type about to be sent is
   multipart/form-data.
 <p>  To post to a form like this with curl, you enter a command line like:
<pre>
 curl --form upload=@localfilename --form press=OK [URL]
</pre>
<a name="Hidden_Fields"></a><h3>4.5 Hidden Fields</h3>
<p>  A very common way for HTML based applications to pass state information
   between pages is to add hidden fields to the forms. Hidden fields are
    already filled in, they aren't displayed to the user and they get passed
    along just as all the other fields.
 <p>  A similar example form with one visible field, one hidden field and one
   submit button could look like:
 <p>    &lt;form method="POST" action="foobar.cgi"&gt;
<pre>
 &lt;input type=text name="birthyear"&gt;
 &lt;input type=hidden name="person" value="daniel"&gt;
 &lt;input type=submit name="press" value="OK"&gt;
</pre>
     &lt;/form&gt;
 <p>  To POST this with curl, you won't have to think about if the fields are
   hidden or not. To curl they're all the same:
 <pre>
 curl --data "birthyear=1905&amp;press=OK&amp;person=daniel" [URL]
</pre>
<a name="Figure_Out_What_A_POST_Looks_Lik"></a><h3>4.6 Figure Out What A POST Looks Like</h3>
<p>  When you're about fill in a form and send to a server by using curl instead
   of a browser, you're of course very interested in sending a POST exactly the
    way your browser does.
 <p>  An easy way to get to see this, is to save the HTML page with the form on
   your local disk, modify the 'method' to a GET, and press the submit button
    (you could also change the action URL if you want to).
 <p>  You will then clearly see the data get appended to the URL, separated with a
   '?'-letter as GET forms are supposed to.
 <h2>5. HTTP upload</h2><a name="PUT"></a><h3>5.1 PUT</h3>
<p> Perhaps the best way to upload data to a HTTP server is to use PUT. Then
  again, this of course requires that someone put a program or script on the
   server end that knows how to receive a HTTP PUT stream.
 <p> Put a file to a HTTP server with curl:
<pre>
 curl --upload-file uploadfile <a href="http://www.example.com/receive.cgi">http://www.example.com/receive.cgi</a>
</pre>
<h2>6. HTTP Authentication</h2><a name="Basic_Authentication"></a><h3>6.1 Basic Authentication</h3>
<p> HTTP Authentication is the ability to tell the server your username and
  password so that it can verify that you're allowed to do the request you're
   doing. The Basic authentication used in HTTP (which is the type curl uses by
   default) is *plain* *text* based, which means it sends username and password
   only slightly obfuscated, but still fully readable by anyone that sniffs on
   the network between you and the remote server.
 <p> To tell curl to use a user and password for authentication:
<pre>
 curl --user name:password <a href="http://www.example.com">http://www.example.com</a>
</pre>
<a name="Other_Authentication"></a><h3>6.2 Other Authentication</h3>
<p> The site might require a different authentication method (check the headers
  returned by the server), and then --ntlm, --digest, --negotiate or even
   --anyauth might be options that suit you.
 <a name="Proxy_Authentication"></a><h3>6.3 Proxy Authentication</h3>
<p> Sometimes your HTTP access is only available through the use of a HTTP
  proxy. This seems to be especially common at various companies. A HTTP proxy
   may require its own user and password to allow the client to get through to
   the Internet. To specify those with curl, run something like:
 <pre>
 curl --proxy-user proxyuser:proxypassword curl.haxx.se
</pre>
<p> If your proxy requires the authentication to be done using the NTLM method,
  use --proxy-ntlm, if it requires Digest use --proxy-digest.
 <p> If you use any one of these user+password options but leave out the password
  part, curl will prompt for the password interactively.
 <a name="Hiding_credentials"></a><h3>6.4 Hiding credentials</h3>
<p> Do note that when a program is run, its parameters might be possible to see
  when listing the running processes of the system. Thus, other users may be
   able to watch your passwords if you pass them as plain command line
   options. There are ways to circumvent this.
 <p> It is worth noting that while this is how HTTP Authentication works, very
  many web sites will not use this concept when they provide logins etc. See
   the Web Login chapter further below for more details on that.
 <h2>7. More HTTP Headers</h2><a name="Referer"></a><h3>7.1 Referer</h3>
<p> A HTTP request may include a 'referer' field (yes it is misspelled), which
  can be used to tell from which URL the client got to this particular
   resource. Some programs/scripts check the referer field of requests to verify
   that this wasn't arriving from an external site or an unknown page. While
   this is a stupid way to check something so easily forged, many scripts still
   do it. Using curl, you can put anything you want in the referer-field and
   thus more easily be able to fool the server into serving your request.
 <p> Use curl to set the referer field with:
<pre>
 curl --referer <a href="http://www.example.come">http://www.example.come</a> <a href="http://www.example.com">http://www.example.com</a>
</pre>
<a name="User_Agent"></a><h3>7.2 User Agent</h3>
<p> Very similar to the referer field, all HTTP requests may set the User-Agent
  field. It names what user agent (client) that is being used. Many
   applications use this information to decide how to display pages. Silly web
   programmers try to make different pages for users of different browsers to
   make them look the best possible for their particular browsers. They usually
   also do different kinds of javascript, vbscript etc.
 <p> At times, you will see that getting a page with curl will not return the same
  page that you see when getting the page with your browser. Then you know it
   is time to set the User Agent field to fool the server into thinking you're
   one of those browsers.
 <p> To make curl look like Internet Explorer 5 on a Windows 2000 box:
<p>  curl --user-agent "Mozilla/4.0 (compatible; MSIE 5.01; Windows NT 5.0)" [URL]
<p> Or why not look like you're using Netscape 4.73 on an old Linux box:
<p>  curl --user-agent "Mozilla/4.73 [en] (X11; U; Linux 2.2.15 i686)" [URL]
<h2>8. Redirects</h2><a name="Location_header"></a><h3>8.1 Location header</h3>
<p> When a resource is requested from a server, the reply from the server may
  include a hint about where the browser should go next to find this page, or a
   new page keeping newly generated output. The header that tells the browser
   to redirect is Location:.
 <p> Curl does not follow Location: headers by default, but will simply display
  such pages in the same manner it displays all HTTP replies. It does however
   feature an option that will make it attempt to follow the Location: pointers.
 <p> To tell curl to follow a Location:
<pre>
 curl --location <a href="http://www.example.com">http://www.example.com</a>
</pre>
<p> If you use curl to POST to a site that immediately redirects you to another
  page, you can safely use --location (-L) and --data/--form together. Curl will
   only use POST in the first request, and then revert to GET in the following
   operations.
 <a name="Other_redirects"></a><h3>8.2 Other redirects</h3>
<p> Browser typically support at least two other ways of redirects that curl
  doesn't: first the html may contain a meta refresh tag that asks the browser
   to load a specific URL after a set number of seconds, or it may use
   javascript to do it.
 <h2>9. Cookies</h2><a name="Cookie_Basics"></a><h3>9.1 Cookie Basics</h3>
<p> The way the web browsers do "client side state control" is by using
  cookies. Cookies are just names with associated contents. The cookies are
   sent to the client by the server. The server tells the client for what path
   and host name it wants the cookie sent back, and it also sends an expiration
   date and a few more properties.
 <p> When a client communicates with a server with a name and path as previously
  specified in a received cookie, the client sends back the cookies and their
   contents to the server, unless of course they are expired.
 <p> Many applications and servers use this method to connect a series of requests
  into a single logical session. To be able to use curl in such occasions, we
   must be able to record and send back cookies the way the web application
   expects them. The same way browsers deal with them.
 <a name="Cookie_options"></a><h3>9.2 Cookie options</h3>
<p> The simplest way to send a few cookies to the server when getting a page with
  curl is to add them on the command line like:
 <pre>
 curl --cookie "name=Daniel" <a href="http://www.example.com">http://www.example.com</a>
</pre>
<p> Cookies are sent as common HTTP headers. This is practical as it allows curl
  to record cookies simply by recording headers. Record cookies with curl by
   using the --dump-header (-D) option like:
 <pre>
 curl --dump-header headers_and_cookies <a href="http://www.example.com">http://www.example.com</a>
</pre>
<p> (Take note that the --cookie-jar option described below is a better way to
  store cookies.)
 <p> Curl has a full blown cookie parsing engine built-in that comes in use if you
  want to reconnect to a server and use cookies that were stored from a
   previous connection (or hand-crafted manually to fool the server into
   believing you had a previous connection). To use previously stored cookies,
   you run curl like:
 <pre>
 curl --cookie stored_cookies_in_file <a href="http://www.example.com">http://www.example.com</a>
</pre>
<p> Curl's "cookie engine" gets enabled when you use the --cookie option. If you
  only want curl to understand received cookies, use --cookie with a file that
   doesn't exist. Example, if you want to let curl understand cookies from a
   page and follow a location (and thus possibly send back cookies it received),
   you can invoke it like:
 <pre>
 curl --cookie nada --location <a href="http://www.example.com">http://www.example.com</a>
</pre>
<p> Curl has the ability to read and write cookie files that use the same file
  format that Netscape and Mozilla once used. It is a convenient way to share
   cookies between scripts or invokes. The --cookie (-b) switch automatically
   detects if a given file is such a cookie file and parses it, and by using the
   --cookie-jar (-c) option you'll make curl write a new cookie file at the end
   of an operation:
 <pre>
 curl --cookie cookies.txt --cookie-jar newcookies.txt  <a href="http://www.example.com">http://www.example.com</a>
</pre>
<h2>10. HTTPS</h2><a name="HTTPS_is_HTTP_secure"></a><h3>10.1 HTTPS is HTTP secure</h3>
<p> There are a few ways to do secure HTTP transfers. By far the most common
  protocol for doing this is what is generally known as HTTPS, HTTP over
   SSL. SSL encrypts all the data that is sent and received over the network and
   thus makes it harder for attackers to spy on sensitive information.
 <p> SSL (or TLS as the latest version of the standard is called) offers a
  truckload of advanced features to allow all those encryptions and key
   infrastructure mechanisms encrypted HTTP requires.
 <p> Curl supports encrypted fetches when built to use a TLS library and it can be
  built to use one out of a fairly large set of libraries - "curl -V" will show
   which one your curl was built to use (if any!). To get a page from a HTTPS
   server, simply run curl like:
 <pre>
 curl <a href="https://secure.example.com">https://secure.example.com</a>
</pre>
<a name="Certificates"></a><h3>10.2 Certificates</h3>
<p>  In the HTTPS world, you use certificates to validate that you are the one
   you claim to be, as an addition to normal passwords. Curl supports client-
    side certificates. All certificates are locked with a pass phrase, which you
    need to enter before the certificate can be used by curl. The pass phrase
    can be specified on the command line or if not, entered interactively when
    curl queries for it. Use a certificate with curl on a HTTPS server like:
 <pre>
 curl --cert mycert.pem <a href="https://secure.example.com">https://secure.example.com</a>
</pre>
<p>  curl also tries to verify that the server is who it claims to be, by
   verifying the server's certificate against a locally stored CA cert
    bundle. Failing the verification will cause curl to deny the connection. You
    must then use --insecure (-k) in case you want to tell curl to ignore that
    the server can't be verified.
 <p>  More about server certificate verification and ca cert bundles can be read
   in the SSLCERTS document, available online here:
 <pre>
 <a href="https://curl.haxx.se/docs/sslcerts.html">https://curl.haxx.se/docs/sslcerts.html</a>
</pre>
<p>  At times you may end up with your own CA cert store and then you can tell
   curl to use that to verify the server's certificate:
 <pre>
 curl --cacert ca-bundle.pem <a href="https://example.com/">https://example.com/</a>
</pre>
<h2>11. Custom Request Elements</h2><a name="Modify_method_and_headers"></a><h3>11.1 Modify method and headers</h3>
<p> Doing fancy stuff, you may need to add or change elements of a single curl
  request.
 <p> For example, you can change the POST request to a PROPFIND and send the data
  as "Content-Type: text/xml" (instead of the default Content-Type) like this:
 <pre>
 curl --data "&lt;xml&gt;" --header "Content-Type: text/xml"  --request PROPFIND url.com
</pre>
<p> You can delete a default header by providing one without content. Like you
  can ruin the request by chopping off the Host: header:
 <pre>
 curl --header "Host:" <a href="http://www.example.com">http://www.example.com</a>
</pre>
<p> You can add headers the same way. Your server may want a "Destination:"
  header, and you can add it:
 <pre>
 curl --header "Destination: <a href="http://nowhere">http://nowhere</a>" <a href="http://example.com">http://example.com</a>
</pre>
<a name="More_on_changed_methods"></a><h3>11.2 More on changed methods</h3>
<p> It should be noted that curl selects which methods to use on its own
  depending on what action to ask for. -d will do POST, -I will do HEAD and so
   on. If you use the --request / -X option you can change the method keyword
   curl selects, but you will not modify curl's behavior. This means that if you
   for example use -d "data" to do a POST, you can modify the method to a
   PROPFIND with -X and curl will still think it sends a POST. You can change
   the normal GET to a POST method by simply adding -X POST in a command line
   like:
 <pre>
 curl -X POST <a href="http://example.org/">http://example.org/</a>
</pre>
<p> ... but curl will still think and act as if it sent a GET so it won't send any
  request body etc.
 <h2>12. Web Login</h2><a name="Some_login_tricks"></a><h3>12.1 Some login tricks</h3>
<p> While not strictly just HTTP related, it still causes a lot of people problems
  so here's the executive run-down of how the vast majority of all login forms
   work and how to login to them using curl.
 <p> It can also be noted that to do this properly in an automated fashion, you
  will most certainly need to script things and do multiple curl invokes etc.
 <p> First, servers mostly use cookies to track the logged-in status of the
  client, so you will need to capture the cookies you receive in the
   responses. Then, many sites also set a special cookie on the login page (to
   make sure you got there through their login page) so you should make a habit
   of first getting the login-form page to capture the cookies set there.
 <p> Some web-based login systems feature various amounts of javascript, and
  sometimes they use such code to set or modify cookie contents. Possibly they
   do that to prevent programmed logins, like this manual describes how to...
   Anyway, if reading the code isn't enough to let you repeat the behavior
   manually, capturing the HTTP requests done by your browsers and analyzing the
   sent cookies is usually a working method to work out how to shortcut the
   javascript need.
 <p> In the actual &lt;form&gt; tag for the login, lots of sites fill-in random/session
  or otherwise secretly generated hidden tags and you may need to first capture
   the HTML code for the login form and extract all the hidden fields to be able
   to do a proper login POST. Remember that the contents need to be URL encoded
   when sent in a normal POST.
 <h2>13. Debug</h2><a name="Some_debug_tricks"></a><h3>13.1 Some debug tricks</h3>
<p> Many times when you run curl on a site, you'll notice that the site doesn't
  seem to respond the same way to your curl requests as it does to your
   browser's.
 <p> Then you need to start making your curl requests more similar to your
  browser's requests:
 <p> * Use the --trace-ascii option to store fully detailed logs of the requests
  for easier analyzing and better understanding
 <p> * Make sure you check for and use cookies when needed (both reading with
  --cookie and writing with --cookie-jar)
 <p> * Set user-agent to one like a recent popular browser does
<p> * Set referer like it is set by the browser
<p> * If you use POST, make sure you send all the fields and in the same order as
  the browser does it.
 <p> A very good helper to make sure you do this right, is the LiveHTTPHeader tool
  that lets you view all headers you send and receive with Mozilla/Firefox
   (even when using HTTPS). Chrome features similar functionality out of the box
   among the developer's tools.
 <p> A more raw approach is to capture the HTTP traffic on the network with tools
  such as ethereal or tcpdump and check what headers that were sent and
   received by the browser. (HTTPS makes this technique inefficient.)
 <h2>14. References</h2><a name="Standards"></a><h3>14.1 Standards</h3>
<p> RFC 7230 is a must to read if you want in-depth understanding of the HTTP
  protocol
 <p> RFC 3986 explains the URL syntax
<p> RFC 1867 defines the HTTP post upload format
<p> RFC 6525 defines how HTTP cookies work
<a name="Sites"></a><h3>14.2 Sites</h3>
<p> <a href="https://curl.haxx.se">https://curl.haxx.se</a> is the home of the curl project
</div>
</div>
</BODY>
</HTML>
